use std::str::str;
use std::libc::{ malloc, free, streq };
use std::io::io;

enum tok_kind {
    tok_null,       # reserved
    tok_num,        # number literal
    tok_str,        # string literal
    tok_ch,         # character literal
    tok_id,         # identifier
    tok_true,       # keyword true
    tok_false,      # keyword false
    tok_use,        # keyword use
    tok_enum,       # keyword enum
    tok_for,        # keyword for
    tok_forindex,   # keyword forindex
    tok_foreach,    # keyword foreach
    tok_while,      # keyword while
    tok_var,        # keyword var
    tok_struct,     # keyword struct
    tok_pub,        # keyword pub
    tok_impl,       # keyword impl
    tok_func,       # keyword func
    tok_break,      # keyword break
    tok_continue,   # keyword continue
    tok_return,     # keyword return
    tok_if,         # keyword if
    tok_elsif,      # keyword elsif
    tok_else,       # keyword else
    tok_nil,        # keyword nil
    tok_lparen,     # (
    tok_rparen,     # )
    tok_lbracket,   # [
    tok_rbracket,   # ]
    tok_lbrace,     # {
    tok_rbrace,     # }
    tok_semi,       # ;
    tok_op_and,     # conditional binary operator and/&&
    tok_op_or,      # conditional binary operator or/||
    tok_comma,      # ,
    tok_dot,        # .
    tok_ellipsis,   # ...
    tok_quesmark,   # ?
    tok_colon,      # :
    tok_coloncolon, # ::
    tok_add,        # +
    tok_sub,        # -
    tok_mul,        # *
    tok_div,        # /
    tok_rem,        # %
    tok_floater,    # bitwise operator not '~'
    tok_bit_and,    # bitwise operator &
    tok_bit_or,     # bitwise operator |
    tok_bit_xor,    # bitwise operator ^
    tok_op_not,     # conditional binary operator !
    tok_eq,         # =
    tok_addeq,      # +=
    tok_subeq,      # -=
    tok_muleq,      # *=
    tok_diveq,      # /=
    tok_remeq,      # %=
    tok_floatereq,  # bitwise operator ~=
    tok_bit_and_eq, # bitwise operator &=
    tok_bit_or_eq,  # bitwise operator |=
    tok_bit_xor_eq, # bitwise operator ^=
    tok_cmp_eq,     # ==
    tok_neq,        # !=
    tok_less,       # <
    tok_leq,        # <=
    tok_grt,        # >
    tok_geq,        # >=
    tok_arrow,      # ->
    tok_wide_arrow, # =>
    tok_eof         # <eof> token
}

func tok_kind_to_str(kind: tok_kind) -> i8* {
    if (kind == tok_kind::tok_null) {
        return "[tok_null      ]";
    } elsif (kind == tok_kind::tok_num) {
        return "[tok_num       ]";
    } elsif (kind == tok_kind::tok_str) {
        return "[tok_str       ]";
    } elsif (kind == tok_kind::tok_ch) {
        return "[tok_ch        ]";
    } elsif (kind == tok_kind::tok_id) {
        return "[tok_id        ]";
    } elsif (kind == tok_kind::tok_true) {
        return "[tok_true      ]";
    } elsif (kind == tok_kind::tok_false) {
        return "[tok_false     ]";
    } elsif (kind == tok_kind::tok_use) {
        return "[tok_use       ]";
    } elsif (kind == tok_kind::tok_enum) {
        return "[tok_enum      ]";
    } elsif (kind == tok_kind::tok_for) {
        return "[tok_for       ]";
    } elsif (kind == tok_kind::tok_forindex) {
        return "[tok_forindex  ]";
    } elsif (kind == tok_kind::tok_foreach) {
        return "[tok_foreach   ]";
    } elsif (kind == tok_kind::tok_while) {
        return "[tok_while     ]";
    } elsif (kind == tok_kind::tok_var) {
        return "[tok_var       ]";
    } elsif (kind == tok_kind::tok_struct) {
        return "[tok_struct    ]";
    } elsif (kind == tok_kind::tok_pub) {
        return "[tok_pub       ]";
    } elsif (kind == tok_kind::tok_impl) {
        return "[tok_impl      ]";
    } elsif (kind == tok_kind::tok_func) {
        return "[tok_func      ]";
    } elsif (kind == tok_kind::tok_break) {
        return "[tok_break     ]";
    } elsif (kind == tok_kind::tok_continue) {
        return "[tok_continue  ]";
    } elsif (kind == tok_kind::tok_return) {
        return "[tok_return    ]";
    } elsif (kind == tok_kind::tok_if) {
        return "[tok_if        ]";
    } elsif(kind == tok_kind::tok_elsif) {
        return "[tok_elsif     ]";
    } elsif (kind == tok_kind::tok_else) {
        return "[tok_else      ]";
    } elsif (kind == tok_kind::tok_nil) {
        return "[tok_nil       ]";
    } elsif (kind == tok_kind::tok_lparen) {
        return "[tok_lparen    ]";
    } elsif (kind == tok_kind::tok_rparen) {
        return "[tok_rparen    ]";
    } elsif (kind == tok_kind::tok_lbracket) {
        return "[tok_lbracket  ]";
    } elsif (kind == tok_kind::tok_rbracket) {
        return "[tok_rbracket  ]";
    } elsif (kind == tok_kind::tok_lbrace) {
        return "[tok_lbrace    ]";
    } elsif (kind == tok_kind::tok_rbrace) {
        return "[tok_rbrace    ]";
    } elsif (kind == tok_kind::tok_semi) {
        return "[tok_semi      ]";
    } elsif (kind == tok_kind::tok_op_and) {
        return "[tok_op_and    ]";
    } elsif (kind == tok_kind::tok_op_or) {
        return "[tok_op_or     ]";
    } elsif (kind == tok_kind::tok_comma) {
        return "[tok_comma     ]";
    } elsif (kind == tok_kind::tok_dot) {
        return "[tok_dot       ]";
    } elsif (kind == tok_kind::tok_ellipsis) {
        return "[tok_ellipsis  ]";
    } elsif (kind == tok_kind::tok_quesmark) {
        return "[tok_quesmark  ]";
    } elsif (kind == tok_kind::tok_colon) {
        return "[tok_colon     ]";
    } elsif (kind == tok_kind::tok_coloncolon) {
        return "[tok_coloncolon]";
    } elsif (kind == tok_kind::tok_add) {
        return "[tok_add       ]";
    } elsif (kind == tok_kind::tok_sub) {
        return "[tok_sub       ]";
    } elsif (kind == tok_kind::tok_mul) {
        return "[tok_mul       ]";
    } elsif (kind == tok_kind::tok_div) {
        return "[tok_div       ]";
    } elsif (kind == tok_kind::tok_rem) {
        return "[tok_rem       ]";
    } elsif (kind == tok_kind::tok_floater) {
        return "[tok_floater   ]";
    } elsif (kind == tok_kind::tok_bit_and) {
        return "[tok_bit_and   ]";
    } elsif (kind == tok_kind::tok_bit_or) {
        return "[tok_bit_or    ]";
    } elsif (kind == tok_kind::tok_bit_xor) {
        return "[tok_bit_xor   ]";
    } elsif (kind == tok_kind::tok_op_not) {
        return "[tok_op_not    ]";
    } elsif (kind == tok_kind::tok_eq) {
        return "[tok_eq        ]";
    } elsif (kind == tok_kind::tok_addeq) {
        return "[tok_addeq     ]";
    } elsif (kind == tok_kind::tok_subeq) {
        return "[tok_subeq     ]";
    } elsif (kind == tok_kind::tok_muleq) {
        return "[tok_muleq     ]";
    } elsif (kind == tok_kind::tok_diveq) {
        return "[tok_diveq     ]";
    } elsif (kind == tok_kind::tok_remeq) {
        return "[tok_remeq     ]";
    } elsif (kind == tok_kind::tok_floatereq) {
        return "[tok_floatereq ]";
    } elsif (kind == tok_kind::tok_bit_and_eq) {
        return "[tok_bit_and_eq]";
    } elsif (kind == tok_kind::tok_bit_or_eq) {
        return "[tok_bit_or_eq ]";
    } elsif (kind == tok_kind::tok_bit_xor_eq) {
        return "[tok_bit_xor_eq]";
    } elsif (kind == tok_kind::tok_cmp_eq) {
        return "[tok_cmp_eq    ]";
    } elsif (kind == tok_kind::tok_neq) {
        return "[tok_neq       ]";
    } elsif (kind == tok_kind::tok_less) {
        return "[tok_less      ]";
    } elsif (kind == tok_kind::tok_leq) {
        return "[tok_leq       ]";
    } elsif (kind == tok_kind::tok_grt) {
        return "[tok_grt       ]";
    } elsif (kind == tok_kind::tok_geq) {
        return "[tok_geq       ]";
    } elsif (kind == tok_kind::tok_arrow) {
        return "[tok_arrow     ]";
    } elsif (kind == tok_kind::tok_wide_arrow) {
        return "[tok_wide_arrow]";
    } elsif (kind == tok_kind::tok_eof) {
        return "[tok_eof       ]";
    }

    return "[unknown token ]";
}

struct token {
    kind: tok_kind,
    content: str*
}

impl token {
    func new(kind: tok_kind, content: str*) -> token* {
        var res = token::__alloc__();
        res->kind = kind;
        res->content = content;
        return res;
    }

    func delete(self: token*) {
        self->content->delete();
        free(self->content => i8*);
        return;
    }
}

struct vec_token {
    data: token*,
    size: u64,
    alloc_size: u64
}

impl vec_token {
    func new() -> vec_token* {
        var res = vec_token::__alloc__();
        var size_of_token = token::__size__();
        res->data = malloc((2048 => u64) * size_of_token) => token*;
        res->size = 0 => u64;
        res->alloc_size = 2048 => u64;
        return res;
    }

    func delete(self: vec_token*) {
        var index = 0 => u64;
        while(index < self->size) {
            self->data[index].delete();
            index += 1 => u64;
        }
        free(self->data => i8*);
        return;
    }

    func append(self: vec_token*, kind: tok_kind, content: str*) {
        if(self->size == self->alloc_size) {
            var size_of_token = token::__size__();
            var new_data = malloc(
                (self->alloc_size * (2 => u64)) * size_of_token
            ) => token*;
            var index = 0 => u64;
            while(index < self->size) {
                new_data[index] = self->data[index];
                index += 1 => u64;
            }
            free(self->data => i8*);
            self->data = new_data;
            self->alloc_size *= 2 => u64;
        }

        self->data[self->size].kind = kind;
        self->data[self->size].content = content;
        self->size += 1 => u64;
        return;
    }
}

struct lexer {
    toks: vec_token*,
    pos: u64
}

impl lexer {
    func new() -> lexer* {
        var res = lexer::__alloc__();
        res->toks = vec_token::new();
        res->pos = 0 => u64;
        return res;
    }

    func delete(self: lexer*) {
        self->toks->delete();
        return;
    }

    func is_identifier_head(c: i8) -> bool {
        return ('a' <= c && c <= 'z') || ('A' <= c && c <= 'Z') || (c == '_');
    }

    func is_identifier_body(c: i8) -> bool {
        return lexer::is_identifier_head(c) || ('0' <= c && c <= '9');
    }

    func is_arrow(pos: u64, src: str*) -> bool {
        if (src->get(pos)!='-') {
            return false;
        }
        if (pos + 1 => u64 < src->size &&
            src->get(pos + 1 => u64)=='>') {
            return true;
        }
        return false;
    }

    func is_wide_arrow(pos: u64, src: str*) -> bool {
        if (src->get(pos)!='=') {
            return false;
        }
        if (pos + 1 => u64 < src->size &&
            src->get(pos + 1 => u64)=='>') {
            return true;
        }
        return false;
    }

    func generate_arrow(self: lexer*, src: str*) {
        var tmp = str::new();
        tmp->append_char(src->get(self->pos));
        self->pos += 1 => u64;
        tmp->append_char(src->get(self->pos));
        self->pos += 1 => u64;
        if (tmp->get(0 => u64)=='-') {
            self->toks->append(tok_kind::tok_arrow, tmp);
        } else {
            self->toks->append(tok_kind::tok_wide_arrow, tmp);
        }
        return;
    }

    func check_id_kind(src: str*) -> tok_kind {
        if (src->eq_const("true")) {
            return tok_kind::tok_true;
        } elsif (src->eq_const("false")) {
            return tok_kind::tok_false;
        } elsif (src->eq_const("use")) {
            return tok_kind::tok_use;
        } elsif (src->eq_const("enum")) {
            return tok_kind::tok_enum;
        } elsif (src->eq_const("for")) {
            return tok_kind::tok_for;
        } elsif (src->eq_const("forindex")) {
            return tok_kind::tok_forindex;
        } elsif (src->eq_const("foreach")) {
            return tok_kind::tok_foreach;
        } elsif (src->eq_const("while")) {
            return tok_kind::tok_while;
        } elsif (src->eq_const("var")) {
            return tok_kind::tok_var;
        } elsif (src->eq_const("struct")) {
            return tok_kind::tok_struct;
        } elsif (src->eq_const("pub")) {
            return tok_kind::tok_pub;
        } elsif (src->eq_const("impl")) {
            return tok_kind::tok_impl;
        } elsif (src->eq_const("func")) {
            return tok_kind::tok_func;
        } elsif (src->eq_const("break")) {
            return tok_kind::tok_break;
        } elsif (src->eq_const("continue")) {
            return tok_kind::tok_continue;
        } elsif (src->eq_const("return")) {
            return tok_kind::tok_return;
        } elsif (src->eq_const("if")) {
            return tok_kind::tok_if;
        } elsif (src->eq_const("elsif")) {
            return tok_kind::tok_elsif;
        } elsif (src->eq_const("else")) {
            return tok_kind::tok_else;
        } elsif (src->eq_const("nil")) {
            return tok_kind::tok_nil;
        } elsif (src->eq_const("and")) {
            return tok_kind::tok_op_and;
        } elsif (src->eq_const("or")) {
            return tok_kind::tok_op_or;
        }
        return tok_kind::tok_id;
    }

    func generate_identifier(self: lexer*, src: str*) {
        var tmp = str::new();
        while(self->pos < src->size &&
              lexer::is_identifier_body(src->get(self->pos))) {
            tmp->append_char(src->get(self->pos));
            self->pos += 1 => u64;
        }

        self->toks->append(lexer::check_id_kind(tmp), tmp);
        return;
    }

    func generate_coloncolon(self: lexer*, src: str*) {
        var tmp = str::new();
        tmp->append_char(':');
        self->pos += 1 => u64;
        if (self->pos < src->size && src->get(self->pos) == ':') {
            tmp->append_char(':');
            self->pos += 1 => u64;
            self->toks->append(tok_kind::tok_coloncolon, tmp);
        } else {
            self->toks->append(tok_kind::tok_colon, tmp);
        }
        return;
    }

    func generate_ellipsis(self: lexer*, src: str*) {
        var tmp = str::new();
        tmp->append_char('.');
        self->pos += 1 => u64;
        if (self->pos + (1 => u64) < src->size &&
            src->get(self->pos) == '.' &&
            src->get(self->pos + (1 => u64)) == '.') {
            tmp->append_char('.')->append_char('.');
            self->pos += 2 => u64;
            self->toks->append(tok_kind::tok_ellipsis, tmp);
        } else {
            self->toks->append(tok_kind::tok_dot, tmp);
        }
        return;
    }

    func skip_note(self: lexer*, src: str*) {
        while(self->pos < src->size && src->get(self->pos) != '\n') {
            self->pos += 1 => u64;
        }
        return;
    }

    func scan(self: lexer*, src: str*) {
        self->pos = 0 => u64;
        while(self->pos < src->size) {
            if (lexer::is_identifier_head(src->get(self->pos))) {
                self->generate_identifier(src);
            } elsif (src->get(self->pos)==':') {
                self->generate_coloncolon(src);
            } elsif (src->get(self->pos)=='.') {
                self->generate_ellipsis(src);
            } elsif (lexer::is_arrow(self->pos, src) ||
                     lexer::is_wide_arrow(self->pos, src)) {
                self->generate_arrow(src);
            } elsif (src->get(self->pos)=='#') {
                self->skip_note(src);
            } else {
                self->pos += 1 => u64;
            }
        }

        self->toks->append(tok_kind::tok_eof, str::new());
        return;
    }

    func dump(self: lexer*) {
        var index = 0 => u64;
        while(index < self->toks->size) {
            io::stdlog()->out(tok_kind_to_str(self->toks->data[index].kind))
                        ->out(" \"")
                        ->out(self->toks->data[index].content->c_str)
                        ->out("\"")
                        ->endln();
            index += 1 => u64;
        }
        return;
    }
}
